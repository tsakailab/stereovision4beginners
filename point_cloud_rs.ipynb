{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYQZsJ7316zA"
   },
   "source": [
    "# RealSenseを使ってみよう（深度画像と点群の観察）\n",
    "### RealSenseを接続してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UFSkEVwutRBD"
   },
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Configure color and depth to run at VGA resolution at 30 frames per second\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth)\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3_GULHX16zL"
   },
   "source": [
    "## カラー画像と深度画像を表示・保存しよう。\n",
    "スペースキーを押す毎に画像が連番で保存されます。'q' を押すと終了します。最後に保存したデータが点群の作成に使われます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2qNjk_GtRBS"
   },
   "outputs": [],
   "source": [
    "# Start streaming\n",
    "pipeline = rs.pipeline()\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "# Get camera parameters\n",
    "intr = profile.get_stream(rs.stream.depth).as_video_stream_profile().get_intrinsics()\n",
    "scale = config.resolve(rs.pipeline_wrapper(pipeline)).get_device().first_depth_sensor().get_depth_scale()\n",
    "\n",
    "# Create a camera alignment object (depth aligned to color)\n",
    "align = rs.align(rs.stream.color)\n",
    "max_depth = 2.0 / scale # Zeros out for any depth greater than 2.0 meters\n",
    "\n",
    "# Display and save images\n",
    "print(\"Press [SPACE] to save images (png) and depth data (npy).\")\n",
    "print(\"Press 'q' to stop.\")\n",
    "nsaved = 0\n",
    "try:\n",
    "    while True:\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned_frames = align.process(frames)\n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "        depth_frame = aligned_frames.get_depth_frame()\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "        bgr = np.asanyarray(color_frame.get_data())\n",
    "        depth = np.asanyarray(depth_frame.get_data())\n",
    "        depth[depth > max_depth] = 0 # Zeros out\n",
    "\n",
    "        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "        depth_colormap = cv2.applyColorMap(cv2.normalize(depth, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U), \n",
    "                                           cv2.COLORMAP_JET)\n",
    "  \n",
    "        images = np.hstack((bgr, depth_colormap))\n",
    "        # Show images\n",
    "        cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RealSense', images)\n",
    "        \n",
    "        key = cv2.waitKey(33)\n",
    "        if key == ord(' '):\n",
    "            Z = depth * scale * 1e+3 # unit in mm\n",
    "            color = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Save images\n",
    "            cv2.imwrite('color{:02d}pc.png'.format(nsaved), bgr)\n",
    "            cv2.imwrite('depth{:02d}pc.png'.format(nsaved), depth_colormap)\n",
    "            np.save('Z{:02d}pc.npy'.format(nsaved), Z)\n",
    "            \n",
    "            print(\"color image and depth data are saved ({:02d})\".format(nsaved))\n",
    "            nsaved += 1\n",
    "\n",
    "        elif key == ord('q'):\n",
    "            if nsaved == 0:\n",
    "                Z = depth * scale * 1e+3 # unit in mm\n",
    "                color = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "finally:\n",
    "    # Stop streaming\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n06_TE8y16zO"
   },
   "source": [
    "### 確認のため，最後に保存したカラー画像と深度画像を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FmUdTtztRBW"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(color)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Z, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CL3StI9816zQ"
   },
   "source": [
    "## 点群を作って観察しよう。\n",
    "\"?????\" を正しい計算式に書き換えてから実行してください。乗算は *，除算は / です。\n",
    "- X = ?????   # Z, u, f による計算式\n",
    "- Y = ?????   # Z, v, f による計算式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMnVo0cOtRBZ"
   },
   "outputs": [],
   "source": [
    "focal_length = intr.fx # in pixels\n",
    "\n",
    "def Zuv_to_XY(Z, u, v, f=focal_length):\n",
    "    X = ?????   # Z, u, f による計算式\n",
    "    Y = ?????   # Z, v, f による計算式\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OWR-JBMtRBa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 主点を設定します．\n",
    "cx, cy = intr.ppx, intr.ppy # width*0.5, height*0.5\n",
    "j_to_u = lambda j: -(j - cx)\n",
    "i_to_v = lambda i: -(i - cy)\n",
    "# 画像平面の座標を設定します．\n",
    "height, width, _ = color.shape\n",
    "u, v = np.meshgrid(j_to_u(np.arange(width)), i_to_v(np.arange(height)))\n",
    "\n",
    "# Z, u, v から X, Y を計算します．\n",
    "X, Y = Zuv_to_XY(Z, u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_p_nPc9jtRBb"
   },
   "outputs": [],
   "source": [
    "# 点群を表示する\n",
    "\n",
    "nd = np.count_nonzero(Z)\n",
    "n = 30000\n",
    "p = np.random.choice(nd, min(n,nd), replace=False)\n",
    "print(\"%d out of %d points are displayed.\" % (n, nd))\n",
    "\n",
    "import plotly.graph_objs  as go\n",
    "rgb = color[Z>0][p] # * 1.5 # brighter\n",
    "\n",
    "trace = go.Scatter3d(x=X[Z>0][p], y=Y[Z>0][p], z=Z[Z>0][p], mode='markers',\n",
    "                     marker=dict(size=2, \n",
    "                                color=['rgb({},{},{})'.format(r,g,b) for r,g,b in zip(rgb[:,0], rgb[:,1], rgb[:,2])],\n",
    "                                opacity=0.8))\n",
    "\n",
    "layout = go.Layout(margin=dict(l=0,r=0,b=0,t=0))\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "camera = dict(up=dict(x=0, y=0, z=1), center=dict(x=0, y=-0.4, z=0), eye=dict(x=0, y=0.8, z=-2))\n",
    "fig.update_layout(scene_camera=camera)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "pointcloud_rs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
